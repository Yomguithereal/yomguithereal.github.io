---
type: deck
draft: false
title: "Dupond & Dupont: La déduplication assistée par ordinateur"
slug: deduplication-seminar
date: "2019-10-01"
lang: fr
event: "Séminaire du médialab"
description:
    A guided tour of deduplication algorithms and their usage in a variety of
    social sciences projects.
---

import Head from 'gatsby-theme-mdx-deck/src/components/head';
import Notes from 'gatsby-theme-mdx-deck/src/components/notes';
import customTheme from '../style/decks-theme.js';
import {Verbatim} from './components/deduplication.js';

import DATA from './data/deduplication.json';

export const theme = customTheme;

<Head>
  <title>Dupond &amp; Dupont - la Déduplication Assistée par Ordinateur</title>
</Head>

<h2>Dupond &amp; Dupont:<br />la déduplication assistée par ordinateur</h2>

### Une visite guidée des algorithmes de déduplication et de leur utilisation dans le cadre de projets en sciences sociales

*Guillaume Plique, Séminaire du médialab de Sciences Po, 01/10/2019*

---

#### Présentation & règles du jeu

Qui a déja utilisé l'outil [Open Refine](http://openrefine.org/) (anciennement Google Refine) ?

<Notes>
  Présentation perso, interruptions, questions et si je pars dans des délires mystiques. Hobby et péché mignon. Fascination pour OpenRefine.
</Notes>

---

#### Les ordinateurs sont stupides

Ces deux chaînes de caractères sont elles similaires ?

<ul>
  <li>
    <Verbatim>Dupond</Verbatim>
  </li>
  <li>
    <Verbatim>Dupont</Verbatim>
  </li>
</ul>

---

#### Les ordinateurs n'ont aucun humour et ne sont pas tolérants à l'erreur

Ces deux chaînes de caractères sont elles similaires ?

<ul>
  <li>
    <code style={{backgroundColor: 'white', padding: '7px'}}>Dupond</code>
  </li>
  <li>
    <code style={{backgroundColor: 'white', padding: '7px'}}>Dupond&nbsp;</code>
  </li>
</ul>

---

#### Les ordinateurs se moquent de la réalité des sciences sociales

* Données d'archives (souvent historiques et pré-orthographe)
* Retranscriptions d'entretiens
* Données d'enquête remplies à plusieurs mains
* Fusions de multiples bases de données

---

#### Comment calculer des agrégations légitimes ?

Le nettoyage à la main et l'huile de coude.

Le cas du projet [TOFLIT18](http://toflit18.medialab.sciences-po.fr):

<ul style={{overflowY: 'scroll', height: '300px', border: '1px dashed black'}}>
  {DATA.merrains.map(item => <li key={item}><code>{item}</code></li>)}
</ul>

---

#### Le travail manuel à l'heure du "Big Data"

TOFLIT18 c'est `~50k` libellés.

Le nettoyage *a la mano* est-il encore possible si on multiplie ce chiffre par 10, 100, 1000 ?

---

#### La déduplication assistée par ordinateur

Démo [Takoyaki](https://yomguithereal.github.io/takoyaki/)

---

#### Un fantasme d'ingénieur (ou de dictature)

Monsieur `identifiant unique n°46251574`

Madame `identifiant unique n°7472575`

*« Ce n'est pas moi qui ai tort, c'est la réalité qui se trompe »*

---

#### Un début de solution

Emuler cet univers alternatif.

Plier les maths à la réalité: la [logique floue](https://en.wikipedia.org/wiki/Fuzzy_logic) de Lofti Zadeh (1965).

---

#### Un problème polymorphe mais pourtant unique

1. `fuzzy matching`: trouver les élements similaires à une requête `q` dans un ensemble `A`.
2. `similarity join`: trouver les similarités de tous les élements d'un ensemble `A` avec ceux d'un ensemble `B`.
3. `fuzzy clustering`: trouver, dans un ensemble `A` toutes les paires d'éléments similaires.

Tous ces problèmes sont mathématiquement **identiques**.

<Notes>
  Appuyer la similarité entre 2. et 3. et bien expliquer le problème 3. qui est celui dont on a fait la démonstration dans Takoyaki.
</Notes>

---

#### De multiples noms, dans des disciplines variées

En botanique, en généalogie, en informatique, en mathétiques etc.

*Similarity Join, Harmonization, Clustering, Fuzzy Clustering, Fuzzy Matching, Deduplication, Record Linkage, Entity Resolution, Consolidation, Canonicalization etc.*

---

## Les fondements algorithmiques

### Comment arrive-t-on à formuler des programmes capables de détecter des doublons potentiels ?

---

## I.
## La normalisation

### Réduire des chaînes de caractère à une clé unique pour permettre à l'ordinateur de les associer

---

#### Des caractères et du sens

Tous les caractères d'une chaîne le même impact sur son "sens". Parfois certaines choses sont optionelles pour la compréhension:

* Les espaces blancs
* La ponctuation
* La casse (majuscule/minuscules)
* Les accents (merci aux anglo-saxons...)

<p>
  <Verbatim>Université&nbsp;&nbsp;&nbsp;&nbsp;de la SORBONNE.</Verbatim>
  &nbsp;=~&nbsp;
  <Verbatim>universite de la sorbonne</Verbatim>
</p>

---

#### "Les Experts: chaîne de caractère" - Le fingerprinting

Il est possible de pousser la logique de normalisation très loin:

* L'ordre des mots
* La répétition des mots

<p>
  <Verbatim>University of north Carolina</Verbatim>
  &nbsp;=~&nbsp;
  <Verbatim>Carolina, North university of</Verbatim>
</p>


[Démo](https://yomguithereal.github.io/talisman/keyers#fingerprint)

---

#### Les algorithmes phonétiques

Les bibliothécaires et le [Soundex](https://en.wikipedia.org/wiki/Soundex) (1918, Russell, Odell).

Lawrence Philips et le [metaphone](https://en.wikipedia.org/wiki/Metaphone).

[Démos](https://yomguithereal.github.io/talisman/phonetics), [Phonogram](https://yomguithereal.github.io/phonogram/)

<p>
  <Verbatim>Michael Quail</Verbatim>
  &nbsp;=~&nbsp;
  <Verbatim>Mickael Quayle</Verbatim>
</p>

<Notes>
  L'ironie de leurs nom propres.
</Notes>

---

#### Les stemmers

Réduction à la "racine" grammaticale d'un mot.

Martin Porter et le [Porter Stemming Algorithm](https://tartarus.org/martin/PorterStemmer/index-old.html).

Ne pas confondre avec le processus de lemmatisation.

[Démos](https://yomguithereal.github.io/talisman/stemmers)

<p>
  <Verbatim>Building</Verbatim>
  &nbsp;=~&nbsp;
  <Verbatim>Build</Verbatim>
</p>

<Notes>
  Martin Porter n'est pas le premier, mais certainement le plus connu.
</Notes>

---

## II.
## La distance

### Quand la normalisation ne suffit pas, il convient de formuler un moyen de déterminer à quel point deux chaînes sont "proches" l'une de l'autre

---

#### La distance de Levenshtein

Distance absolue mesurant la distance entre deux chaînes exprimée en nombre d'opérations à effectuer pour transformer l'une en l'autre:

1. Substitution
2. Addition
3. Deletion
4. Damerau: transposition

<p>
  Levenshtein(
  <Verbatim>Levenshtein</Verbatim>
  ,&nbsp;
  <Verbatim>Levensthein</Verbatim>
  ) = <code>2</code>
</p>

[Démo](https://yomguithereal.github.io/talisman/metrics/distance#levenshtein)

<Notes>
  C'est une véritable distance métrique (au sens mathématique du terme).
</Notes>

----

#### La similarité de Jaccard

Intersection de l'ensemble des caractères de deux chaînes sur leur union.

Naturellement exprimée entre `0` et `1`, ce qui la rend plus facile à interpréter.

<p>
  Jaccard(
  <Verbatim>context</Verbatim>
  ,&nbsp;
  <Verbatim>contact</Verbatim>
  ) = <code>4/7</code>
</p>

[Démo](https://yomguithereal.github.io/talisman/metrics/distance#jaccard)

<Notes>
  Distance et son inverse: la similarité.
</Notes>

---

## III.
## L'appariement

### Maintenant que nous pouvons comparer des chaînes, comment constituer des paires de doublons potentiels ?

---

#### Le cas trivial - la distance identité

Grouper des chaînes par clé identique est un problème résolu en informatique.

Hashmaps, tris, arbres etc. `O(n)` ou `O(n log n)`.

---

#### La solution naïve

Il suffit de calculer la similarité de toutes les paires de notre jeu de données.

Il y a `(n * (n - 1)) / 2` paires possibles.

Le problème est donc quadratique `O(n²)`.

---

#### La solution naïve

* `100` => `4 950` paires
* `1000` => `499 500` paires
* `10 000` => `49 995 000` paires

En sus, les métriques de distance/similarité sont souvent couteuses.

Cette solution ne passe pas à l'échelle.

---

#### Optimisations

* `Transitive`: *Blocking, Sorted Neighborhood Method*
* `Spatiale`: *Indexation de l'espace métrique (Vantage Point Trees)*
* `Spécialisée`: *PPJoin, PassJoin etc.*
* `Probabiliste`: *NN Descent, Minhashing*

<Notes>
  Il existe des méthodes mais elles ont toutes des inconvénients ou des spécialisations.
</Notes>

---

## Aller plus loin

### Comment améliorer les outils existants et comment rendre leur pratique plus évidente et efficace ?

---

## I.
## Le Machine Learning

### A l'ère de l'apprentissage automatique, n'existe-t-il pas une méthode magique pour résoudre notre problème ?

---

<h2 style={{textAlign: 'center'}}>Non</h2>

---

#### L'échec relatif des méthodes classiques

Il existe bien des modèles supervisés ou non (e.g. Fellegi-Sunter).

Leur scores ne sont pas réjouissants dans la plupart des cas.

Ce qui est certain: il faudra probablement entraîner un modèle spécifique à votre jeu de données (surtout en sciences sociales).

Temps pour entraîner le modèle =~ Faire le nettoyage à la main.

<Notes>
  Je suis un peu catastrophiste mais à une échelle méso ça se tient.
</Notes>

---

#### Pourquoi cela marche-t-il mal ?

1. Les features que l'on peut trouver dans le jeu de données ne corrèlent quasiment jamais avec le fait d'être un doublon ou pas.
2. Le fait que plusieurs méthodes détectent la même paire n'est pas pertinent pour juger de la probabilité que cette paire soit un vrai doublon.

*La probabilité qu'une paire soit un vrai doublon n'a que peu de variables dépendantes.*

---

#### Frustration quantitative

Il est par ailleurs difficile d'estimer véritablement le nombre de doublons d'un jeu de données.

Quantifier ce nombre correspond à résoudre le problème en entier.

Il convient d'être très prudent avec les méthodes d'échantillonage classiques tant ce problème a tendance à échapper aux distributions usuelles.

---

#### Une alternative hybride: les systèmes de scoring

Par des méthodes heuristiques ou statistique, il reste possible de *scorer* les paires pour assister l'humain.

Mais il y a un risque: générer beaucoup de faux négatifs.

C'est une bonne stratégie pour éviter un maximum de faux positifs dans le cas d'une déduplication automatisée.

---

#### Le cas du projet BHHT

[A brief history of human time](https://hal.archives-ouvertes.fr/hal-01440325)

Des millions de pages wikipedia.

Des centaines de milliers de doublons potentiels.

---

#### Le paradoxe des anniversaires

[Lien](https://fr.wikipedia.org/wiki/Paradoxe_des_anniversaires)

23 personnes = 1 chance sur 2

Les gens sont en général mauvais juges des probabilités.

---

#### Le rapport avec la choucroute

1. Quelle est la probabilité, sur Wikipedia, que 2 individus aient un nom similaire, la même date de naissance et de mort et la même occupation?
2. Parfois le dé est pipé.

[Tim Coronel](https://en.wikipedia.org/wiki/Tim_Coronel) & [Tom Coronel](https://en.wikipedia.org/wiki/Tom_Coronel)

[Lauren Vélez](https://fr.wikipedia.org/wiki/Lauren_V%C3%A9lez) & [Lorraine Vélez](https://en.wikipedia.org/wiki/Lorraine_V%C3%A9lez)

---

#### La fréquence est-elle un bon garde-fou ?

Si un individu est célèbre, i.e. a une importance statistique dans mon jeu de données, alors les doublons sont moins probables?

Ou la fréquence des deux individus d'une paires conditionne la probabilité du doublon?

Non. Mais il convient probablement de vérifier ces cas-là en priorité car ils affectent bien plus vos agrégations.

---

#### Charles Dickens le botaniste

<p style={{overflowY: 'scroll', overflowX: 'scroll', height: '300px', border: '1px dashed black', padding: '20px', fontFamily: 'monospace', whiteSpace: 'pre'}}>
  {DATA.bhht.map(item => <span key={item}>{item}<br /></span>)}
</p>

---

#### Et si vos features sont erronées :) ?

---

## II.
## Vers une meilleure UX

### Les outils doivent s'améliorer et accompagner l'utilisateur dans la compréhension des heuristiques mobilisées

<!--

Les solutions probabilistes, les solutions spécialisées

TODO: revenir sur toflit et le pourquoi du pas assisté 1. parce qu'on savait pas 2. parce exige des compétences métiers

TODO: ajouter le lien de la prez au début

TODO: problème du bon cluster, et de l'UX

TODO: Ricardo: prévenir en amont en équipant les chercheurs

- Le bon cluster & le mauvais cluster et son radius (les 3 méthodes de fog): dominance de la composante connexe pour ce genre de travail?

Projets:
- TOFLIT18 -> à la main, titanesque (peu de méthode appropriée)
- Ricardo
- LIEPP, bhht
- Projet Russe

- Quid du machine learning? prétérition sur ma propre pratique
- Fellegi Sunter
- Problème intéressant: ça marche pas. parce que les features ne sont quasiment jamais corrélées au fait d'être un doublon ou pas. le fait que plusieurs méthodes matchent n'est pas pertinent non plus
- Système hybride de scoring par heuristique (cf. Dominique) bien pour trouver les plus probables mais ignore tous les autres
- Pour le quanti: Estimer le nombre de doublons n'est pas non plus facile
- Pudeur des sciences sociales + le fait que la corrélation notoriété n'est pas évidente
- Anecdote des gens nés le même jour et de la classe qui rigole: à partir d'un seuil critique de données, les coincidences sont fort probables -> besoin de l'humain
  https://fr.wikipedia.org/wiki/Paradoxe_des_anniversaires 23 personnes = 1 chance sur 2
- Exemple des jumelles & tim and tom coronel:
  https://fr.wikipedia.org/wiki/Lauren_V%C3%A9lez
  https://en.wikipedia.org/wiki/Lorraine_V%C3%A9lez
- Charles Dickens, la notoriété/frequence/importance comme garde fou? -> dur à avaler quand on veut les meilleurs agrégations possibles

- l'optimisation algorithmique par spécialisation de distance

- Ce qui marche mieux ça reste de cribler les méthodes: besoin d'enregistrer les faux négatifs (enjeux d'UX et de compréhension: considérer les paires ou les clusters), on crible de la méthode la moins agressive à la plus agresive

Q5686 Charles_Dickens 48 clustering_0b_exact 0.75
Q21510353 Charles_Dickens 3148774.5 clustering_0b_exact 0.75

Enjeux
- Besoin de pédagogie de l'outil parce besoin de méthodes tailored
- Pas de silver bullet
- On est dans un échelle méso, quali-quanti
- Besoin de méthodes non anglo-saxone (carry -> donato)
- Objectif dans le big data: reduire les faux positifs et faux négatifs: le soundex ça marche plus, à notre échelle (truc de bibliothécaire)
- Le clustering est très sparse, problème: Visualiser l'espace métrique (dimensions log n) n'est pas aisé mais des interfaces d'exploration du problème seraient cool, Exemple de TOFLIT18 et du réseau de Paul
- Le fuzzy matching de Ricardo pour insertion de données au fil de l'eau

Ouvertures
- Liens avec la génétique / biologie, généalogie (découvertes parallèles), Levenshtein = botaniste -> faire une digression
- Les outils, Open Refine et Takoyaki
- Fog, talisman, phonogram, rusalka

-->
